{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpgxPsbecen/7B9Lr/xTJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyunMooKim/Deep-learning_from-the-bottom/blob/main/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>밑바닥부터 시작하는 딥러닝 1 </h1>"
      ],
      "metadata": {
        "id": "rUx8wY0ClSjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2장 퍼셉트론\n",
        "AND, OR, NAND, XOR\n",
        "등 가장 기본적 논리구조를 표현하는 방식\n",
        "\n",
        " W.dot(x) + b 형태는 SVM 의 손실함수와 비슷한 형태\n"
      ],
      "metadata": {
        "id": "8hQxesAaj14Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 퍼셉트론\n",
        "import numpy as np\n",
        "\n",
        "# np.array() 는 리스트를 받아서 배열로 만들어준다.\n",
        "# np.sum()은 모든 원소의 총합을 구한다.\n",
        "# 가중치 w는 각 신호의 영향력을, bias 편향력은 얼마나 쉽게 퍼셉트론이 활성화되는지를 나타낸다.\n",
        "\n",
        "def AND(x1,x2):\n",
        "  x = np.array([x1,x2])\n",
        "  w = np.array([0.5,0.5])\n",
        "  b = -0.7   # 0.5 하나론 못넘고, 두개로는 넘어야함.\n",
        "  tmp = np.sum(w*x)  + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def NAND(x1,x2):\n",
        "  x = np.array([x1,x2])\n",
        "  w = np.array([-0.5, -0.5]) #AND에 bias와 가중치 부호 반대로 하면 된다.\n",
        "  b =  0.7\n",
        "  tmp = np.sum(w*x)  + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def OR(x1,x2):\n",
        "  x = np.array([x1,x2])\n",
        "  w = np.array([0.5,0.5])\n",
        "  b = -0.2  #0.5 하나만으로도 넘을 수 있어야 한다.\n",
        "  tmp = np.sum(w*x)  + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "#퍼셉트론으로 XOR 게이트를 표현할 수 없다. 비선형 영역이기 때문이다.\n",
        "#다층 퍼셉트론으로 표현한다. ]\n",
        "#NAND로 둘 다인 경우 제외, OR로 둘 다 아닌 경우 제외 이 둘을 AND로 묶어 XOR을 만들어 낸다.\n",
        "def XOR(x1,x2):\n",
        "  s1 = NAND(x1,x2)\n",
        "  s2 = OR(x1,x2)\n",
        "  y = AND(s1,s2)\n",
        "  return y\n",
        "\n",
        "print(XOR(0,0))\n",
        "print(XOR(1,0))\n",
        "print(XOR(0,1))\n",
        "print(XOR(1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhNUs9Xbj456",
        "outputId": "dd27a6ee-1375-4d35-d552-7767aaf044a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3장 신경망\n",
        "퍼셉트론과 신경망의 차이점은, 퍼셉트론은 활성화를 0보다 크거나 작은 경우 2가지로 계단식함수를 이용.\n",
        "\n",
        "반면 신경망은 시그모이드 함수 e^x /(1 + e^x)  = 1/(1+e^-x) 를 이용 \n",
        "\n",
        "https://gooopy.tistory.com/52"
      ],
      "metadata": {
        "id": "iTRywD3zyLtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.array([-1.0, 1.0, 2.0])\n",
        "y = x > 0\n",
        "print(y)\n",
        "# 이렇게 배열에 대하여 부등호 연산을 하면 boolean값이 되는 점을 이용해 계단식 함수에 인자로 배열을 전달할 수 있게 개조\n",
        "\n",
        "def step_function(x):\n",
        "  return np.array(x>0, dtype=np.int )\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "print(step_function(x))\n",
        "y = step_function(x)\n",
        "plt.plot(x,y)\n",
        "plt.ylim(-0.1,1.1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "y = sigmoid(x)\n",
        "plt.plot(x,y)\n",
        "plt.ylim(-0.1,1.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "lFtHXeyMyNUB",
        "outputId": "d3855ee9-97b2-408e-b539-22a99e7a61b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False  True  True]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5e9a4e0001ff>:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return np.array(x>0, dtype=np.int )\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 매끄러워진 함수가 신경망 학습에서 아주 중요한 역할을 하게 된다.\n",
        "\n",
        "1과 0만 반환하는 계단 함수대신 소수를 반환하여 연속적인 실수가 흐르게 된다.\n",
        "\n",
        "최근에는 0이 넘으면 출력하고 0 이하면 0을 출력하는 ReLu 함수를 이용한다."
      ],
      "metadata": {
        "id": "OpjpSx4c0rla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def Relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = Relu(x)\n",
        "plt.plot(x,y)\n",
        "plt.ylim(-0.1,1.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "23AmjaAp1QQG",
        "outputId": "7b3e5bc1-5acd-46c2-9190-24d6cf6dc530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3장 행렬"
      ],
      "metadata": {
        "id": "CvDoSapc17BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "A=np.array([[1,2,3],[4,5,6]])\n",
        "B= np.array([ [1,2],[3,4],[5,6] ])\n",
        "print('A',A)\n",
        "print()\n",
        "print('B',B)\n",
        "#차원\n",
        "print('\\n차원',np.ndim(B))\n",
        "#모양\n",
        "print('\\n모양',B.shape)\n",
        "print()\n",
        "#행렬곱\n",
        "print(np.dot(A,B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESaFs5Ed1-hm",
        "outputId": "dd50188f-1050-41d7-f718-a781b9c55795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A [[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "B [[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "\n",
            "차원 2\n",
            "\n",
            "모양 (3, 2)\n",
            "\n",
            "[[22 28]\n",
            " [49 64]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3장 - 3층 시그모이드 신경망 구현\n",
        "\n",
        "<img src='https://ifh.cc/g/7MZLl1.jpg' border='0'></a>\n"
      ],
      "metadata": {
        "id": "Ows_9urfAnw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def identity_function(x):\n",
        "  return x\n",
        "\n",
        "def init_network():\n",
        "  network={}\n",
        "  #0층에서 1층(노드 2개 -> 3개)\n",
        "  network['W1'] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])\n",
        "  network['b1'] = np.array([0.1,0.2,0.3])\n",
        "\n",
        "  #1층에서 2층(노드3개->2개)\n",
        "  network['W2'] = np.array([[0.1,0.4],[0.2,0.5],[0.3, 0.6]])\n",
        "  network['b2'] = np.array([0.1,0.2])\n",
        "\n",
        "  #2층에서 3층(노드2개->2개)\n",
        "  network['W3'] = np.array([[0.1,0.3],[0.2,0.4]])\n",
        "  network['b3'] = np.array([0.1,0.2])\n",
        "\n",
        "  return network\n",
        "\n",
        "def forward(network, x):\n",
        "  W1,W2,W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1,b2,b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "  a1=np.dot(x,W1) +b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2=np.dot(z1,W2) +b2\n",
        "  z2 = sigmoid(a2)\n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = identity_function(a3)\n",
        "  \n",
        "  return y\n",
        "\n",
        "network=init_network()\n",
        "x = np.array([1.0, 0.5])\n",
        "y = forward(network, x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhzs8JIArlL",
        "outputId": "f2114fa4-b3bf-4fd8-af06-c266cbeef330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31682708 0.69627909]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Soft MAX\n",
        "세 개 이상의 class로 나뉠 경우, 각 class 에 속할 확률\n",
        "\n",
        "설명: https://wikidocs.net/35476 <br>\n",
        "      https://bookandmed.tistory.com/39 "
      ],
      "metadata": {
        "id": "LwD9IgYGNhgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#각 점수\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "\n",
        "#e의 x제곱\n",
        "exp_a = np.exp(a)\n",
        "\n",
        "#분모\n",
        "sum_exp_a = np.sum(exp_a)\n",
        "\n",
        "#각 클래스로 분류될 확률\n",
        "y = exp_a / sum_exp_a\n",
        "\n",
        "print(y)\n",
        "\n",
        "#함수화\n",
        "\n",
        "def softmax(a):\n",
        "  exp_a=np.exp(a)\n",
        "  sum = np.sum(exp_a)\n",
        "  y = exp_a / sum\n",
        "  return y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQXQnixfOC64",
        "outputId": "c6b938a5-1bc3-4cdb-b87f-447c73589ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.01821127 0.24519181 0.73659691]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이때, e의 제곱을 이용하면 오버플로우가 발생할 수 있다.\n",
        "# 이 문제를 해결하기 위해 계산해야할 점수의 최댓값을 모든 점수에 빼주어 상대적 크기 차이만 이용할 수 있다.\n",
        "# page 93을 보면, exp() 함수 안에 상수를 더하거나 빼주어도 값이 변하지 않음을 증명한다.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a-c) #overflow 방지\n",
        "  sum = np.sum(exp_a)\n",
        "  y = exp_a / sum\n",
        "  return y\n",
        "\n",
        "a = np.array([1010,1000,990])\n",
        "result =  softmax(a)\n",
        "print(result)\n",
        "print(np.sum(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osxRif06UJ1G",
        "outputId": "bbedd17e-44da-44ae-bcd9-f3d182afc366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3장 손글씨 숫자 인식"
      ],
      "metadata": {
        "id": "70rzAmg-aRfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#아래 두개 셀을 실행해 데이터 가져와야 뒤에 것들도 가능"
      ],
      "metadata": {
        "id": "3zS8xtrhu7qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjWOYkTAA08s",
        "outputId": "ecf63f15-7bcc-4a54-932f-920956699bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 12.71 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 가져오기\n",
        "import sys, os \n",
        "from deep.dataset import mnist\n",
        "''' \n",
        "완전 처음 할 때 \n",
        "1. git허브에서 가져오기\n",
        "2. sys.path에 내가 쓸 파일 추가하기\n",
        "3. 폴더 이름을 deep으로 바꾸기( - 나 from 때문에 문법오류난다)\n",
        "4. from 바꾼 폴더이름 import 내가 쓸 함수 파일이름\n",
        "'''\n",
        "# 훈련 이미지 6만장, test이미지 만장 \n",
        "\n",
        "# sys.path.append('/content/deep-learning-from-scratch/dataset/mnist.py')\n",
        "# print(sys.path)\n",
        "\n",
        "\n",
        "# https://raw.githubusercontent.com/WegraLee/deep-learning-from-scratch/master/dataset/mnist.py\n",
        "# https://github.com/WegraLee/deep-learning-from-scratch.git \n",
        "\n",
        "#x_train은 이미지, t_train은 라벨\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_mnist(flatten=True, normalize=False)\n",
        "print(x_train.shape) #60000, 784 나오면 성공"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YpWRb5haU-D",
        "outputId": "67ac57cc-5949-4d72-dce0-3adcbc9d83a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 열어보기\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from deep.dataset import mnist\n",
        "from matplotlib.pyplot import imshow \n",
        "\n",
        "def img_show(img):\n",
        "  pil_img = Image.fromarray(np.uint8(img))\n",
        "  imshow(pil_img)\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label) #5\n",
        "\n",
        "print(img.shape) # (784, )\n",
        "img = img.reshape(28, 28) \n",
        "# 원래 이미지의 모양으로 변형 flastten=True 1차원 배열로 저장되어있기 때문에, 28*28로 다시 바꾸는 것\n",
        "print(img.shape)  #(28,28)\n",
        "\n",
        "img_show(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "op3OviKCBBHy",
        "outputId": "7ae7893a-3771-4626-f48a-a4c25d61619d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "(784,)\n",
            "(28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 구현하기\n",
        "# 28*28 크기의 이미지가 input, 0~9의 숫자가 output\n",
        "import os, sys\n",
        "import pickle\n",
        "# sys.path.append('/content/deep-learning-from-scratch/ch03/sample_weight.pkl')\n",
        "# from deep.ch03 import sample_weight 왜인지 .py와 다르게 .pkl은 이렇게 import할 수 없었다 \n",
        "# 대신 실제 경로를 이용해 사용할 수 있었다. /content/deep/ch03/sample_weight.pkl\n",
        "\n",
        "from deep.dataset import mnist\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "  \n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a-c) #overflow 방지를 위해 최대값을 다 빼준다. 결과는 변하지 않는다.\n",
        "  sum = np.sum(exp_a)\n",
        "  y = exp_a / sum\n",
        "  return y\n",
        "\n",
        "def get_data():\n",
        "  #normalize정규화(0~255의 픽셀 값을 0~1 범위로 정규화) 이걸 안하니까 sigmoid에서 runtime error발생\n",
        "  (x_train, t_train), (x_test, t_test) = mnist.load_mnist(flatten=True, normalize=True, one_hot_label=False) #정답만 1, 나머진 0으로 표시하는 원 핫\n",
        "  return x_test, t_test\n",
        "\n",
        "def init_network(): # 가중치와 매개변수가 주어졌다! 딕셔너리로 저장되어있는 이진파일. 최적의 가중치를 찾아내는게 딥러닝\n",
        "  with open(\"/content/deep/ch03/sample_weight.pkl\", 'rb') as f:\n",
        "    network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "#          X            W1          W2            W3          ->        Y\n",
        "#   test개수 x 784   784 x 50    50 x 100    100 x 분류개수     test개수 x 분류개수\n",
        "def predict(network,x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2 = np.dot(z1,W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "  a3 = np.dot(z2,W3) + b3\n",
        "  y = softmax(a3)\n",
        "  return y\n",
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "accuracy_cnt = 0\n",
        "for i in  range(len(x)): #test는 10000개\n",
        "  y = predict(network, x[i])\n",
        "  p = np.argmax(y)  #확률이 가장 높은 인덱스 저장\n",
        "  if (p == t[i]):\n",
        "    accuracy_cnt += 1\n",
        "\n",
        "print('sigmoid 함수, softmax방식 이용한 정확도:', float(accuracy_cnt) / len(x) ) #0.9352가 나와야 정상"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziAjVjlxD3wh",
        "outputId": "9aa4f2fa-839a-4e3f-b43a-2e034479c851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid 함수, softmax방식 이용한 정확도: 0.9352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch 묶음 - x[i] y[i] 에 각각 i번째 이미지와 그 결과가 저장되어 있다.\n",
        "#묶음을 이용해 계산한다. 컴퓨터는 큰 배열을 한번에 계산하는 것이 분할된 배열을 여러번 하는 것보다 빠르다.\n",
        "batch_size = 100\n",
        "accuracy_cnt = 0\n",
        "for i in range(0,len(x), batch_size): \n",
        "  x_batch = x[i:i+batch_size] # 100개의 행, 100개의 test \n",
        "  y_batch = predict(network,x_batch) \n",
        "  p = np.argmax(y_batch, axis=1 ) #100개 단위니까 열따라 이동(행으로) 100번\n",
        "  accuracy_cnt +=np.sum( p == t[i:i+batch_size] )  #조건에 맞는 것만 sum\n",
        "print( float(accuracy_cnt) / len(x) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV8vYQgG8zJb",
        "outputId": "a5726002-95f1-441c-de38-b8c7be507f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4장 신경망 학습 - 수치 미분\n",
        "\n",
        "직선으로 분리할 수 있는 선형 분리 가능 문제는 퍼셉트론 수렴정리에 의해 유한 번의 학습을 통해 풀 수 있다.\n",
        "하지만 비선형 분리 문제는 자동으로 학습할 수 없다.<br>\n",
        "\n",
        "사람이 생각한 특징 -> 기계학습 -> 결과<br>\n",
        "딥러닝 -> 결과 (사람의 개입 최소화)<br><br>\n",
        "\n",
        "'특징'은 보통 SITF, SURF, HOG 등의 특징을 이용해 벡터로 기술하고, 이후 지도 학습 분류 기법 SVM KNN 등으로 학습할 수 있다.\n",
        "\n",
        "정확도가 아닌 손실을 지표로 하는 이유: <br>\n",
        "정확도를 지표로 삼으면 대부분의 매개변수 미분 값이 0으로, 갱신을 하기가 어려워진다. (정확도 32%라면 가중치가 조금 바뀌어도 그대로 32%일 수 있다. 반면 손실함수는 조금의 변화에도 바뀌는 연속적인 변화!)\n",
        "\n",
        "이는 계단식 함수 대신 시그모이드 같은 함수를 이용하는 이유이기도 하다. "
      ],
      "metadata": {
        "id": "1PNG4mMp-01L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 측정 - 오차 제곱의 합\n",
        "import numpy as np\n",
        "#SSE 오차 제곱의 합\n",
        "def sum_squares_error(y, t):\n",
        "  return 0.5 * np.sum((y-t)**2)\n",
        "\n",
        "#정답은 2\n",
        "t= [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "# 2일 확률이 가장 높다고 예측\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print('정답 2를 맞춘 경우 손실',sum_squares_error(np.array(y),np.array(t)) )\n",
        "\n",
        "# 7일 확률이 가장 높다고 예측\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print('틀린 경우 손실', sum_squares_error(np.array(y),np.array(t)) )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmtdIqUZ-3WK",
        "outputId": "3d64433d-168f-453d-9ad3-d3dea5bbe546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 2를 맞춘 경우 손실 0.09750000000000003\n",
            "틀린 경우 손실 0.5975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 측정 - 교차 엔트로피 오차\n",
        "# 로그 씌워서 파악, 정답 인덱스의 점수가 1에 가까울 수록 0에 가까운 손실 발생\n",
        "import numpy as np\n",
        "\n",
        "# (1/N) * -시그마log(y) \n",
        "# 원핫 코딩으로 인해, 정답 인덱스가 아닌 부분은 다 0이 된다. 따라서 데이터가 하나면 추론 결과값의 -log 값이 된다.\n",
        "# 예를들어 2 가 정답이고 그 확률이 0.6인 경우 -log 0.6 이다. 값이 음수니까 앞에 - 부호를 붙여준 것.\n",
        "\n",
        "def cross_entropy_error(y,t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t * np.log(y + delta))\n",
        "  # 아주 작은 델타를 더해줘 np.log에 0이 입력되어 -inf가 되지 않도록 함.\n",
        "\n",
        "#정답은 2\n",
        "t= [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "# 2일 확률이 가장 높다고 예측\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "# - (log 6 - log 10)\n",
        "print('정답 2를 맞춘 경우 손실',cross_entropy_error(np.array(y),np.array(t)) )\n",
        "\n",
        "\n",
        "# 7일 확률이 가장 높다고 예측\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print('틀린 경우 손실', cross_entropy_error(np.array(y),np.array(t)) )\n",
        "# - (log5 - log100) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQZ_-RI1PNoF",
        "outputId": "be1ee202-b6ad-420a-c8ed-6a6b76fe1899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 2를 맞춘 경우 손실 0.510825457099338\n",
            "틀린 경우 손실 2.302584092994546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터 중 무작위 일부만을 이용할 수도 있다. mini-batch 학습이라고 한다.\n",
        "import numpy as np\n",
        "from deep.dataset import mnist\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "train_size = x_train.shape[0] #6만\n",
        "batch_size = 10\n",
        "# 0 이상 6만 미만의 수 중 무작위 10개 선택 ->배열로 나옴\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "\n",
        "# 무작위로 뽑힌 배열을 이용해 원하는 만큼의 데이터와 정답을 가져온다.\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]\n",
        "\n",
        "#이렇게 뽑은 mini-batch로 손실함수를 계산하면 적은 수를 이용할 수 있다.\n",
        "#위에서 구현한 데이터가 하나인 경우와 batch로 묶여 들어오는 경우 모두에 쓸 수 있도록\n",
        "def cross_entropy_error_mini_batch(y,t):\n",
        "  if (y.ndim ==1):\n",
        "    t = t.reshape(1,t.size)\n",
        "    y = y.reshape(1,y.size)\n",
        "  batch_size = y.shape[0]\n",
        "  # 아주 작은 델타를 더해줘 np.log에 0이 입력되어 -inf가 되지 않도록 함.\n",
        "  return -np.sum(t * np.log(y+1e-7)) / batch_size\n",
        "\n",
        "#만약 one hot incoding이 아니라 '2', '7' 등 정답 인덱스인 경우\n",
        "def cross_entropy_error_no_one_hot(y,t):\n",
        "  if (y.ndim ==1):\n",
        "    t = t.reshape(1,t.size)\n",
        "    y = y.reshape(1,y.size)\n",
        "  batch_size = y.shape[0]\n",
        "  #np.arange( 숫자 ) 는 0부터 숫자 -1 까지의 배열을 반환한다.\n",
        "  #y[np.arange(batch_size),t] 는 모든 행에 대한 정답 열을 의미한다.\n",
        "  return -np.sum(t * np.log(y[np.arange(batch_size),t]+1e-7  )) / batch_size   "
      ],
      "metadata": {
        "id": "6vDuCbK3WQzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 위한 미분\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def function_1(x):\n",
        "  return 0.01*x**2 + 0.1*x\n",
        "  \n",
        "def numerical_diff(f,x):\n",
        "  h = 1e-4 #10의 -4제곱! 너무 작게 하면 0으로 인식하는 문제 발생 이정도가 좋다고 알려져있다\n",
        "  return ( f(x+h) - f(x-h) ) / (2*h)    #h를 0으로 무한히 좁히는 것이 불가능하므로, x에서 앞뒤로 h만큼 이동한 실제 미분과 다른 근사치\n",
        "  \n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = function_1(x)\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.plot(x,y)\n",
        "plt.show()\n",
        "\n",
        "print('5에서 미분 이론값 : ', numerical_diff(function_1, 5))\n",
        "print('10에서 미분: ', numerical_diff(function_1, 10) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "odeRfTAcw1e6",
        "outputId": "21693d8f-7c6e-4d71-a9c7-169a398b0d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5에서 미분 이론값 :  0.1999999999990898\n",
            "10에서 미분:  0.2999999999986347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient - 편미분 값을 벡터로 정리한 것\n",
        "# 변수 x 역시 배열 형태로 x = [x1,x2]\n",
        "def function_2(x):\n",
        "  return x[0]**2 + x[1]**2 \n",
        "\n",
        "# 함수와 변수 값들을 받아 미분값 반환\n",
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x) #x와 형상이 같은 배열 생성\n",
        "  \n",
        "  # 변수 개수 만큼 반복문이 돌아야 하는데, 한번만 도는 문제 발생.. -> return 들여쓰기 문제였음\n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "    #각 변수에 대하여 x+h, x-h 계산\n",
        "    x[idx] = tmp_val + h \n",
        "    fxh1 = f(x)\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "\n",
        "    #원래 값으로 복원\n",
        "    x[idx] = tmp_val \n",
        "\n",
        "  return grad\n",
        "\n",
        "\n",
        "print('3차원(2변수 함수) 미분',numerical_gradient( function_2, np.array([3.0, 4.0]) )  )\n",
        "print('3차원(2변수 함수) 미분',numerical_gradient( function_2, np.array([0.0, 2.0]) )  )\n",
        "print('3차원(2변수 함수) 미분',numerical_gradient( function_2, np.array([3.0, 0.0]) )  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KD2JdCK21vU",
        "outputId": "ec907a9f-59f7-48fd-c404-b7e86e40be55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3차원(2변수 함수) 미분 [6. 8.]\n",
            "3차원(2변수 함수) 미분 [0. 4.]\n",
            "3차원(2변수 함수) 미분 [6. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 미분값들을 구해 복잡한 함수에서 최소(혹은 최대)값을 향해 조금씩 이동하며 기울기가 0이 되는 최저점을 찾으려는 방법을 경사 하강법 이라고 한다.<br>\n",
        "그러나 실제 복잡한 현실문제에서는 안정점이 최솟값이 아닐수도 있고, 평평한 곳으로 가면서 고원(플래토)라고 하는 학습이 진행되지 않는 정체기에 빠질 수 있다."
      ],
      "metadata": {
        "id": "1DaDwmgx8A2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경사법으로 x1^2 + x2^2 의 최솟값 구하기\n",
        "def function_2(x):\n",
        "  return x[0]**2 + x[1]**2 \n",
        "\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "  x = init_x\n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f,x)\n",
        "    x = x - lr*grad\n",
        "  return x\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "\n",
        "# 실제 최솟값 0과 아주 비슷 ! 학습률이 너무 크거나 작으면 동떨어진 값이 나온다. (너무 크게 크게 이동하며 찾기 때문)\n",
        "gradient_descent(function_2, init_x = init_x, lr= 0.1, step_num=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvVP_i-48eVl",
        "outputId": "599d5f8b-48c5-4fe0-e3d0-b43c60b6f489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률 처럼 자동 학습이 안되고 여러 후보 중 결정해야 하는 가중치를 hyper parameter라고 한다."
      ],
      "metadata": {
        "id": "2eg0GTUcDntn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망에서의 기울기\n",
        "import numpy as np\n",
        "# !git clone 하고, deep으로 바꾸는 것 잊지 말고!\n",
        "from deep.common.functions import softmax, cross_entropy_error\n",
        "from deep.common.gradient import numerical_gradient\n",
        "\n",
        "class simpleNet:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.randn(2,3) #정규 분포로 초기화\n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.W) \n",
        "  def loss(self, x, t):\n",
        "    z = self.predict(x)\n",
        "    y = softmax(z)\n",
        "    loss = cross_entropy_error(y, t)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# 하나의 신경망 만들기\n",
        "net = simpleNet()\n",
        "print('created Neural Network\\n',net.W)\n",
        "\n",
        "# 초기값 설정 및 예측\n",
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print('predict \\n',p)\n",
        "\n",
        "t = np.array([0, 0, 1]) # 정답 레이블 설정\n",
        "\n",
        "print('compare with the answer loss is: ',net.loss(x, t))\n",
        "\n",
        "\n",
        "\n",
        "# 함수를 손실함수로 정의\n",
        "def f(W):\n",
        "  return net.loss(x,t)\n",
        "# f = lambda w: net.loss(x,t) 로도 가능\n",
        "\n",
        "# 함수와 값을 받아 미분\n",
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1p_B1RB0FUI",
        "outputId": "c36658c0-6d6a-46f7-dc1e-f2e751c35588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created Neural Network\n",
            " [[-0.35932157 -0.07975365 -0.77576032]\n",
            " [ 1.5024245   0.95197443 -0.80141077]]\n",
            "predict \n",
            " [ 1.13658911  0.8089248  -1.18672588]\n",
            "compare with the answer loss is:  2.9213543890610794\n",
            "[[ 0.32993199  0.2377506  -0.56768259]\n",
            " [ 0.49489799  0.3566259  -0.85152389]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 프레임워크 중 SGD (stochastic gradient descent) 방법이 있다.\n",
        "이는 \n",
        "\n",
        "1. 미니배치 무작위 선택\n",
        "2. 기울기 산출\n",
        "3. 매개 변수 갱신 \n",
        "\n",
        "의 3단계를 반복하는 함수이다.\n",
        "즉, 복잡한 매개변수 공간에서(아주 큰 n차원) 기울어진 방향으로 매개변수 값을 갱신하는 일을 몇 번이고 반복하는 단순한 방법."
      ],
      "metadata": {
        "id": "tHWdGU1m6olO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2층 신경망 클래스 구현\n",
        "import numpy as np\n",
        "# !git clone 하고, deep으로 바꾸는 것 잊지 말고!\n",
        "from deep.common.functions import softmax, cross_entropy_error\n",
        "from deep.common.gradient import numerical_gradient\n",
        "from deep.dataset.mnist import load_mnist\n",
        "\n",
        "# 0층 input -> 1층 hidden -> 2층 output\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "  # 가중치 초기화 , 정규분포를 따르는 난수로 가중치 초기화, 0으로 편향 초기화\n",
        "    self.params = {} #create a dictionary\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "    return y\n",
        "        \n",
        "\n",
        "    # x:입력 데이터, t:정답 레이블\n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    return cross_entropy_error(y, t)\n",
        "    \n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    t = np.argmax(t, axis=1)\n",
        "        \n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "    return grads\n",
        " \n",
        "    '''       \n",
        "    def gradient(self, x, t):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        grads = {}\n",
        "        \n",
        "        batch_num = x.shape[0]\n",
        "        \n",
        "        # forward\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        \n",
        "        # backward\n",
        "        dy = (y - t) / batch_num\n",
        "        grads['W2'] = np.dot(z1.T, dy)\n",
        "        grads['b2'] = np.sum(dy, axis=0)\n",
        "        \n",
        "        da1 = np.dot(dy, W2.T)\n",
        "        dz1 = sigmoid_grad(a1) * da1\n",
        "        grads['W1'] = np.dot(x.T, dz1)\n",
        "        grads['b1'] = np.sum(dz1, axis=0)\n",
        "\n",
        "        return grads\n",
        "   '''\n",
        "\n",
        "\n",
        "# 미니배치 학습 구현\n",
        "(x_train, t_trian), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True )\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "# hyper parameter\n",
        "iters_num = 10\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "#input 이미지(28*28) ouput 0~9 숫자 \n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "  print(i)\n",
        "  # mini batch   0~60000 중 100개\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "  # 기울기 계산\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "\n",
        "\n",
        "  # 매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  #학습 기록\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "CBew-7S9679I",
        "outputId": "d50de33a-1a3b-42ed-dcee-5eeb4b2297b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cd90bc84d642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0;31m# grad = network.gradient(x_batch, t_bath)  위에 주석 처리 해 놓은 성능 개선된 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd90bc84d642>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep/common/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mfxh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x+h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd90bc84d642>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# x : 입력 데이터, t : 정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd90bc84d642>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# x:입력 데이터, t:정답 레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd90bc84d642>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 손실이 줄었는지 확인  - 안 줄었다?? \n",
        "# 1바퀴에 1분 걸려서 더 못하겠다. \n",
        "# 알고 보니 뒤에 나오는 오차역전파법이 훨씬 빠르다. 책에서도 그 방법을 이용해 그림을 그렸을듯.\n",
        "plt.plot( range(1,iters_num+1)  , train_loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "iFZrjyp3FQTk",
        "outputId": "875fb00c-44db-44e2-9925-50df00e0ab1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5c2fd01a00>]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch - 훈련 데이터만큼 학습 했을 때의 단위이다.\n",
        "# 즉, 6만 개 사진을 100 미니배치씩 했다면, 600회가 1에폭이다.\n",
        "# 과적합을 막기 위해, 1 epoch이 될때마다 test데이터와 train데이터 정확도를 비교하여 과적합 발생 시점을 찾을 수 있다.\n",
        "\n",
        "#위의 코드와 달라진 점만 보면 된다.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# !git clone 하고, deep으로 바꾸는 것 잊지 말고!\n",
        "from deep.common.functions import softmax, cross_entropy_error, sigmoid\n",
        "from deep.common.gradient import numerical_gradient\n",
        "from deep.dataset.mnist import load_mnist\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "    self.params = {} #create a dictionary\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "    return y\n",
        "        \n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    return cross_entropy_error(y, t)\n",
        "    \n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    t = np.argmax(t, axis=1)\n",
        "        \n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "    return grads\n",
        " \n",
        "\n",
        "(x_train, t_trian), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True )\n",
        "train_loss_list = []\n",
        "\n",
        "iters_num = 10\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "##########################달라진곳############################\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "##########################-----############################\n",
        "\n",
        "for i in range(iters_num):\n",
        "  print(i)\n",
        "  # mini batch   0~60000 중 100개\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "  # 기울기 계산\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "\n",
        "  # 매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  #학습 기록\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  ##########################달라진곳############################\n",
        "  if i % iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(x_train, t_train)\n",
        "    test_acc = network.accurancy(x_test, t_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(\"train acc, test acc | \" + str(train_acc) +\",\" + str(test_acc) )\n",
        "  ##########################-----############################"
      ],
      "metadata": {
        "id": "uy26lG03NlZb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "916100c4-f324-409e-d0eb-b23ebaa4b237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-04a96631e9f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;31m# 기울기 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;31m# grad = network.gradient(x_batch, t_bath)  위에 주석 처리 해 놓은 성능 개선된 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-04a96631e9f0>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep/common/gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-04a96631e9f0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-04a96631e9f0>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-04a96631e9f0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5장 신경망학습 - 오차역전파법  backward propagation\n",
        "<br>cs231n에 나오는 계산 그래프와 연쇄법칙!\n",
        "chain rule을 이용해 미분을 빠르게 만들어준다.\n",
        "위의 방법은 100개 mini-batch를 미분해 갱신하는 데에 1분이 걸렸다."
      ],
      "metadata": {
        "id": "Hs_M1fVDaOzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMed0U1BuLb2",
        "outputId": "3bc4aa69-aa85-41b0-a7e0-695025ddc1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 19.92 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아주 간단한 사과 구매 계산 그래프 = P * Q * T\n",
        "# 곱셈 Layer\n",
        "class MulLayer:\n",
        "  #self.x,  self.y 는 각 노드마다 따로 만들게 된다.\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    out = x * y\n",
        "    return out\n",
        "  # 단순 곱셈이므로 서로가 미분값이 된다. \n",
        "  def backward(self, dout):\n",
        "    dx = dout * self.y\n",
        "    dy = dout * self.x\n",
        "    return dx,dy\n",
        "P = 100\n",
        "Q = 2\n",
        "T = 1.1\n",
        "\n",
        "#계층들\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "#순전파\n",
        "PQ = mul_apple_layer.forward(P,Q)\n",
        "Total_Cost = mul_tax_layer.forward(PQ, T)\n",
        "\n",
        "print(Total_Cost)\n",
        "\n",
        "#역전파\n",
        "#첫 시작은 1로 두 곱셈이 서로 미분값, 그 후로는 chain처럼 계속 곱해나간다.\n",
        "dTotal_Cost = 1\n",
        "dPQ, dT = mul_tax_layer.backward(dTotal_Cost)\n",
        "dP, dQ = mul_apple_layer.backward(dPQ)\n",
        "print(dP,dQ,dT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWsHkZHjaupc",
        "outputId": "79ddc906-e4a3-45f1-868c-213e362580b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220.00000000000003\n",
            "2.2 110.00000000000001 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid 노드 구현\n",
        "import numpy as np\n",
        "\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None\n",
        " \n",
        "  def forward(self, x):\n",
        "    out = 1 / (1 + np.exp(-x))\n",
        "    self.out = out\n",
        "    return out\n",
        "\n",
        " # page 167 ~ 170에 왜 시그모이드의 편미분 chain이 y(1-y) 가 되는지 나온다. \n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "    return dx"
      ],
      "metadata": {
        "id": "UC7nSC-jjkpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#affine 구현 \n",
        "#위에서 한 계산 그래프를 행렬 단위로 진행.\n",
        "# common.layers.py에 있는 affine함수 구현은 4차원 데이터까지 가능한 버전\n",
        "\n",
        "class Affine:\n",
        "  def __init__(self,W,b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dw = None\n",
        "    self.db = None\n",
        "  def forward(self,x):\n",
        "    self.x=x\n",
        "    out = np.dot(x, self.W) + self.b\n",
        "    return out \n",
        "  #스칼라는 아니지만, 어쨋든 곱셈이므로 결국 곱한 상대가 미분값\n",
        "  def backward(self, dout):\n",
        "    dx = np.dot(dout,self.W.T)\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    #편향은 상수아닌가? 미분값이 있나?\n",
        "    self.db = np.sum(dout,axis=0)\n",
        "    return dx"
      ],
      "metadata": {
        "id": "rE1v3Xhqg-PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soft max with loss 노드 구현\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.loss = None #loss\n",
        "    self.y = None  #softmax 의 출력\n",
        "    self.t = None  #정답 label(one-hot vector)\n",
        "  \n",
        "  def forward(self, x, t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x)\n",
        "    self.loss = cross_entropy_error(self.y, self.t)\n",
        "    return self.loss\n",
        "  \n",
        "  def backward(self, dout=1):\n",
        "    batch_size = self.t.shape[0]\n",
        "    dx = (self.y - self.t) / batch_size\n",
        "    return dx\n",
        "  \n"
      ],
      "metadata": {
        "id": "A1NtlzQMnnko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차역전파법을 적용한 신경망 구현\n",
        "\n",
        "import numpy as np\n",
        "from deep.common.gradient import numerical_gradient\n",
        "# layer.py에 가서 common 앞에 deep넣어주어야함.\n",
        "from deep.common.layers import *\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "    self.params = {} #create a dictionary\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "  #계층생성 - 순서가 있는 딕셔너리를 이용, 순전파는 순서대로 역전파는 반대로\n",
        "    self.layers = OrderedDict()\n",
        "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "    self.layers['Relu1'] = Relu()\n",
        "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "    \n",
        "    self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers.values():\n",
        "      x = layer.forward(x)\n",
        "    return x\n",
        "  \n",
        "  def loss(self, x,t):\n",
        "    y = self.predict()\n",
        "    return self.lastLayer.forward(y,t)\n",
        "\n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    #one hot vector라면 1을 정답 인덱스로\n",
        "    if t.ndim != 1 : t = np.argmax(t, axis = 1 )\n",
        "      \n",
        "    accuracy = np.sum(y==t) / float(x.shape[0])\n",
        "    return accuracy \n",
        "\n",
        "  def gradient(self, x,t ):\n",
        "    #순전파\n",
        "    self.loss(x,t)\n",
        "\n",
        "    #역전파\n",
        "    dout=1\n",
        "    dout = self.lastLayer.backward(dout)\n",
        "\n",
        "    layers=list(self.layers.values())\n",
        "    layers.reverse()\n",
        "    for layer in layers:\n",
        "      dout=layer.backward(dout)\n",
        "    #result\n",
        "    grads = {}\n",
        "    grads['W1'] = self.layers['Affine1'].dW\n",
        "    grads['b1'] = self.layers['Affine1'].db\n",
        "    grads['W2'] = self.layers['Affine2'].dW\n",
        "    grads['b2'] = self.layers['Affine2'].db\n",
        "\n",
        "    return grads\n",
        "    "
      ],
      "metadata": {
        "id": "1byvqUsoqmlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#먼저 했던 수치 미분과 나중해 했던 오차역전파법 중\n",
        "# 구현이 쉽지만 더 느린 수치 미분은 오차역전파법이 제대로 되었는지 확인할 때 쓰인다.\n",
        "# 바로 위 코드 돌리고 돌려야함\n",
        "from deep.dataset.mnist import load_mnist\n",
        "from deep.ch05.two_layer_net import TwoLayerNet\n",
        "\n",
        "(x_train, t_trian), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True )\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "x_batch = x_train[:3]\n",
        "t_batch = t_trian[:3]\n",
        "\n",
        "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "for key in grad_numerical.keys():\n",
        "  diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
        "  print(key + \":\" + str(diff))\n",
        "# 아주 작은 오차면 성공!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-UxozAtxqBm",
        "outputId": "7cafaf6d-e639-4359-fb9f-ec64513b5530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:4.77772187953562e-10\n",
            "b1:2.9894537577492648e-09\n",
            "W2:6.546715693493958e-09\n",
            "b2:1.3924283003008409e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오류가 없었다면, 이제 신경망 학습을 수치 미분이 아니라 오차역전법으로 진행해보자.\n",
        "# 수치 미분은 아주 오래 걸렸던 것을 기억하라!\n",
        "from deep.dataset.mnist import load_mnist\n",
        "from deep.ch05.two_layer_net import TwoLayerNet\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, t_trian), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True )\n",
        "train_loss_list = []\n",
        "\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "  # mini batch   0~60000 중 100개\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "  ###############4장과 달라진 곳#######################\n",
        "  # grad = network.numerical_gradient(x_batch, t_batch)\n",
        "  grad = network.gradient(x_batch, t_batch) \n",
        "\n",
        "  # 매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  #학습 기록\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i % iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(x_train, t_train)\n",
        "    test_acc = network.accuracy(x_test, t_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(\"train acc, test acc | \" + str(train_acc) +\",\" + str(test_acc) )\n",
        "\n",
        "#train acc 와 test acc가 차이가 많이 나면 과적합!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJy7CAuuz8Ho",
        "outputId": "a0e722de-308c-4a7b-f738-8dede4e77682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc, test acc | 0.08555,0.0851\n",
            "train acc, test acc | 0.9023833333333333,0.9069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 손실이 줄었는지 확인이 된다! \n",
        "plt.plot( range(1,iters_num+1)  , train_loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "JcCk4z_Z1lJR",
        "outputId": "aa7bd2a1-a589-47b6-aa0a-bd87c0b04d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0db7139c40>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6장 학습 관련 기술들"
      ],
      "metadata": {
        "id": "JReknB7JLt2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>최적화 방법</h4>\n",
        "1. 기울기를 계속 갱신하며 최적점을 찾아가는 SDG\n",
        "<br>-단순한 방법\n",
        "<br>-가장 가파른 기울기가 가르키는 방향이 최적점과 먼 경우 비효율적\n",
        "<br><br>\n",
        "2. momentum 운동량\n",
        "<br>-이전 갱신의 velocity를 구해 momentum을 곱하여 학습에 더해준다..(첫 V는 0)\n",
        "<br>- V = momentum * (이전 V) - learning rate * grad\n",
        "<br>+ 기울기는 V에 - , -기울기는 V에 +\n",
        "따라서 같은 방향으로 계속 움직이면 일정하게 가속하고, 지그재그 움직임은 가속도가 일정하지 않게 된다. page 196에 더 효율적인 경우가 나온다.\n",
        "<br><br>\n",
        "3. AdaGrad\n",
        "<br>-매개변수가 갱신되어 감에 따라 학습률을 감소 시킨다.\n",
        "<br>-더 많이 갱신될 수록 더 많이 감소\n",
        "<br><br>\n",
        "4. Adam - momentum + AdaGrad\n",
        "<br><br>\n",
        "모든 상황에 맞는 뛰어난 기법이란 없다. 상황에 맞게 써야 한다. "
      ],
      "metadata": {
        "id": "l9RzUqPGLxWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>가중치 초기값으로 인한 기울기 소실문제:</h4>\n",
        "<bt>\n",
        "<br>초기값이 너무 크면 시그모이드 함수의 출력이 0과 1에 가까워질 때 그 미분은 0에 다가간다. 따라서 데이터가 0과 1에 치우쳐 분포하게 되면 기울기가 점점 작아지다가 사라진다. 층을 깊게 하는 딥러닝일수록 더 심각한 문제가 될 수 있다.\n",
        "<br>\n",
        "1. ReLU 를 이용할 때는, He초깃값을\n",
        "<br>\n",
        "2. sigmoid나 tanh 등 S자 모양 곡선일 때는 Xavier를 초깃값으로 하는 것이 모범사례\n",
        "<br>\n",
        "3. batch noramization을 이용할 수도 있다.\n",
        "<br> mini batch 입력데이터를 평균0, 분산 1 인 정규분포로 정규화하여 데이터가 덜 치우지게 만드는 방법.\n"
      ],
      "metadata": {
        "id": "KGaCGplyhTIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Over Fitting</h4>\n",
        "<br>매게 변수가 많고 복잡한 모델이나 훈련 데이터가 적은 경우 발생 가능\n",
        "<br>\n",
        "1. 가중치 감소 방법: W절댓값의 합, 제곱합의 루트 등 정규화 항을 손실 함수에 더하여 과적합 방지. 1/2 入 W^2\n",
        "2. dropout: 훈련 때 무작위로 노드를 삭제하여 학습하고 test 때는 모든 뉴런에 신호를 전달한다. 단, test 시 각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱하여 출력한다. "
      ],
      "metadata": {
        "id": "HVPwv6onlyKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>data 나누기</h4>\n",
        "1. 훈련 데이터: 매개변수 학습\n",
        "<br>2. 검증 데이터: 하이퍼파라미터 성능 평가\n",
        "<br>3. 시험 데이터: 신경망의 범용 성능 평가"
      ],
      "metadata": {
        "id": "Ydh8gcxhpwHO"
      }
    }
  ]
}